# üöÄ Gu√≠a Completa de Deployment - SaccharumVision API

## üìã Tabla de Contenidos
1. [Resumen de Opciones](#resumen-de-opciones)
2. [Opci√≥n 1: Hugging Face Spaces (RECOMENDADO)](#opci√≥n-1-hugging-face-spaces)
3. [Opci√≥n 2: Google Colab + ngrok](#opci√≥n-2-google-colab-ngrok)
4. [Opci√≥n 3: Render.com](#opci√≥n-3-rendercom)
5. [Configuraci√≥n de la App M√≥vil](#configuraci√≥n-de-la-app-m√≥vil)
6. [Testing y Debugging](#testing-y-debugging)
7. [Troubleshooting](#troubleshooting)

---

## üìä Resumen de Opciones

| Opci√≥n | Costo | GPU | Persistencia | Dificultad | Recomendado |
|--------|-------|-----|--------------|------------|-------------|
| **Hugging Face Spaces** | Gratis | ‚úÖ S√≠ (T4) | ‚úÖ Permanente | ‚≠ê‚≠ê F√°cil | ‚úÖ **S√ç** |
| **Google Colab + ngrok** | Gratis | ‚úÖ S√≠ (T4/V100) | ‚ùå Temporal | ‚≠ê‚≠ê‚≠ê Media | ‚ö†Ô∏è Para testing |
| **Render.com** | Gratis | ‚ùå Solo CPU | ‚úÖ Permanente | ‚≠ê Muy f√°cil | ‚ö†Ô∏è Alternativa |

---

## üéØ Opci√≥n 1: Hugging Face Spaces (RECOMENDADO)

### ¬øPor qu√© Hugging Face?
- ‚úÖ **100% gratuito** con GPU T4
- ‚úÖ Deployment permanente 24/7
- ‚úÖ URLs p√∫blicas estables
- ‚úÖ Logs en tiempo real
- ‚úÖ No requiere tarjeta de cr√©dito
- ‚úÖ F√°cil actualizaci√≥n del modelo

### Paso a Paso

#### 1. Crear Cuenta
```
1. Ve a https://huggingface.co/
2. Clic en "Sign Up"
3. Verifica tu email
4. ¬°Listo! No se requiere pago
```

#### 2. Crear un Space
```
1. Click en tu perfil ‚Üí "Spaces" ‚Üí "Create new Space"
2. Configuraci√≥n:
   - Name: saccharumvision-api
   - License: MIT
   - SDK: Docker
   - Hardware: CPU basic (gratis) o GPU T4 small (tambi√©n gratis!)
   - Visibility: Public (recomendado) o Private
3. Clic en "Create Space"
```

#### 3. Subir Archivos

Estructura de archivos necesaria:
```
your-space/
‚îú‚îÄ‚îÄ app.py                    ‚Üê C√≥digo de la API (ya creado)
‚îú‚îÄ‚îÄ requirements.txt          ‚Üê Dependencias (ya creado)
‚îú‚îÄ‚îÄ Dockerfile               ‚Üê Configuraci√≥n Docker (ya creado)
‚îú‚îÄ‚îÄ model.keras              ‚Üê TU MODELO ORIGINAL ‚ö†Ô∏è
‚îî‚îÄ‚îÄ README.md                ‚Üê Documentaci√≥n (opcional)
```

**IMPORTANTE**: Debes copiar los archivos de la carpeta `server/` a tu Space.

##### Opci√≥n A: Subir por Web (F√°cil)
```
1. En tu Space, clic en "Files" ‚Üí "Add file" ‚Üí "Upload files"
2. Arrastra estos archivos desde tu carpeta `server/`:
   - app.py
   - requirements.txt
   - Dockerfile
3. IMPORTANTE: Sube tambi√©n tu archivo model.keras original
4. Clic en "Commit changes to main"
```

##### Opci√≥n B: Git (Avanzado)
```powershell
# Clona tu space
git clone https://huggingface.co/spaces/TU-USUARIO/saccharumvision-api
cd saccharumvision-api

# Copia archivos
copy ..\server\app.py .
copy ..\server\requirements.txt .
copy ..\server\Dockerfile .
copy ..\ruta\a\tu\modelo\model.keras .

# Sube a HF
git add .
git commit -m "Initial API deployment"
git push
```

#### 4. Configurar Modelo

Edita `app.py` si es necesario:

```python
# Ajusta seg√∫n tu modelo:

# 1. Tama√±o de imagen
IMG_SIZE = 224  # Cambia si tu modelo usa otro tama√±o

# 2. Clases
CLASS_NAMES = {
    0: "Healthy",
    1: "Mosaic",
    2: "RedRot",
    3: "Rust",
    4: "Yellow"
}

# 3. Preprocesamiento (CR√çTICO)
def preprocess_image(image_bytes: bytes) -> np.ndarray:
    # Opci√≥n A: Sin normalizaci√≥n (0-255)
    img_array = img_array
    
    # Opci√≥n B: Normalizaci√≥n 0-1 (m√°s com√∫n)
    img_array = img_array.astype(np.float32) / 255.0
    
    # Opci√≥n C: ImageNet normalization
    img_array = tf.keras.applications.resnet50.preprocess_input(img_array)
```

#### 5. Build y Deploy

Hugging Face construir√° autom√°ticamente:
```
1. Ve a tu Space
2. Ver√°s "Building" en la esquina superior
3. Espera 5-10 minutos
4. Si hay errores, los ver√°s en "Logs"
5. Cuando veas "Running", ¬°est√° listo! ‚úÖ
```

#### 6. Obtener tu URL

Tu API estar√° en:
```
https://TU-USUARIO-saccharumvision-api.hf.space
```

Ejemplo:
```
https://alexisjr2004-saccharumvision-api.hf.space
```

#### 7. Probar API

```powershell
# Health check
curl https://TU-USUARIO-saccharumvision-api.hf.space/health

# Predicci√≥n (con una imagen)
curl -X POST https://TU-USUARIO-saccharumvision-api.hf.space/predict `
  -F "file=@corn_leaf.jpg"
```

---

## üß™ Opci√≥n 2: Google Colab + ngrok

### ‚ö†Ô∏è Nota: Es temporal, se desconecta al cerrar sesi√≥n

### Ventajas
- ‚úÖ GPU muy potente (T4, V100)
- ‚úÖ Completamente gratis
- ‚úÖ Setup r√°pido

### Desventajas
- ‚ùå Solo funciona mientras Colab est√° abierto
- ‚ùå Se desconecta despu√©s de inactividad
- ‚ùå URL cambia cada vez

### Paso a Paso

#### 1. Crear Notebook en Colab
```
1. Ve a https://colab.research.google.com/
2. File ‚Üí New notebook
3. Runtime ‚Üí Change runtime type ‚Üí GPU (T4)
```

#### 2. Instalar Dependencias
```python
!pip install fastapi uvicorn python-multipart tensorflow pillow pyngrok
```

#### 3. Subir tu Modelo
```python
from google.colab import files

# Subir model.keras
uploaded = files.upload()
# Selecciona tu archivo model.keras
```

#### 4. Crear API
```python
# Copia el c√≥digo de server/app.py aqu√≠
# (mismo c√≥digo que para Hugging Face)
```

#### 5. Configurar ngrok
```python
from pyngrok import ngrok

# Obt√©n tu token gratis en: https://dashboard.ngrok.com/signup
ngrok.set_auth_token("TU_TOKEN_AQUI")

# Crear t√∫nel
public_url = ngrok.connect(7860)
print(f"üåê API p√∫blica en: {public_url}")
```

#### 6. Ejecutar Server
```python
import uvicorn
import nest_asyncio

nest_asyncio.apply()

# Ejecutar en background
uvicorn.run(app, host="0.0.0.0", port=7860)
```

#### 7. Usar URL en tu App
```
La URL ser√° algo como:
https://abc123def456.ngrok.io

‚ö†Ô∏è Esta URL cambia cada vez que ejecutas
```

---

## üîß Opci√≥n 3: Render.com

### Ventajas
- ‚úÖ Gratis permanente (plan free)
- ‚úÖ Deployment autom√°tico desde GitHub
- ‚úÖ SSL gratis

### Desventajas
- ‚ùå Solo CPU (sin GPU)
- ‚ùå Predicciones lentas (~2-5 segundos)
- ‚ùå Se "duerme" despu√©s de 15 min inactivo

### Paso a Paso

#### 1. Preparar Repositorio

Crea estructura en GitHub:
```
saccharumvision-api/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ model.keras          ‚Üê Sube con Git LFS
‚îî‚îÄ‚îÄ README.md
```

**Git LFS para modelo grande**:
```bash
git lfs install
git lfs track "*.keras"
git add .gitattributes
git add .
git commit -m "Add model"
git push
```

#### 2. Deploy en Render
```
1. Ve a https://render.com/
2. Sign up (gratis)
3. New ‚Üí Web Service
4. Connect tu repo de GitHub
5. Configuraci√≥n:
   - Name: saccharumvision-api
   - Environment: Python 3
   - Build Command: pip install -r requirements.txt
   - Start Command: uvicorn app:app --host 0.0.0.0 --port $PORT
   - Plan: Free
6. Create Web Service
```

#### 3. Variables de Entorno (opcional)
```
PORT=10000 (autom√°tico)
PYTHON_VERSION=3.10
```

#### 4. URL
```
Tu API estar√° en:
https://saccharumvision-api.onrender.com
```

**‚ö†Ô∏è Nota sobre "sleeping"**:
- Despu√©s de 15 min sin requests, se "duerme"
- Primer request tarda ~30-60 segundos en "despertar"
- Requests subsecuentes son normales

---

## üì± Configuraci√≥n de la App M√≥vil

### 1. Configurar URL de API

Edita `services/apiService.ts`:
```typescript
// Actualiza con tu URL real de Hugging Face
private API_URL = 'https://TU-USUARIO-saccharumvision-api.hf.space';
```

O configura din√°micamente desde settings:
```typescript
// En tu pantalla de settings
import modelService from '../services/modelService';

// Permitir que usuario configure URL
modelService.setAPIUrl('https://tu-api.hf.space');
```

### 2. Configurar Modo de Modelo

```typescript
// En app/_layout.tsx o donde inicialices
import modelService from './services/modelService';

// Opci√≥n 1: Solo API remota (recomendado)
modelService.setModelType('remote');

// Opci√≥n 2: Solo local
modelService.setModelType('local');

// Opci√≥n 3: Auto (intenta remoto, fallback a local)
modelService.setModelType('auto');
```

### 3. Usar en tu App

No necesitas cambiar nada m√°s, el c√≥digo ya est√° preparado:

```typescript
// En camera.tsx o donde hagas predicci√≥n
import modelService from '../services/modelService';

const result = await modelService.predict(imageUri, false);

console.log('Top prediction:', result.topPrediction.className);
console.log('Confidence:', result.topPrediction.confidence);
console.log('Model used:', result.modelType); // Ver√°s si us√≥ API o local
```

---

## üß™ Testing y Debugging

### Test desde Terminal

```powershell
# Health check
curl https://tu-api.hf.space/health

# Predict con imagen
curl -X POST https://tu-api.hf.space/predict `
  -F "file=@test_image.jpg" `
  | jq  # Formatea JSON
```

### Test desde App

Agrega bot√≥n de test en settings:

```typescript
const testAPI = async () => {
  const result = await apiService.testConnection();
  
  Alert.alert('Test de API', `
    Alcanzable: ${result.reachable ? '‚úÖ' : '‚ùå'}
    Latencia: ${result.latency}ms
    Modelo cargado: ${result.modelLoaded ? '‚úÖ' : '‚ùå'}
    ${result.error ? `Error: ${result.error}` : ''}
  `);
};
```

### Ver Logs

**Hugging Face**:
```
1. Ve a tu Space
2. Click en "Logs" (esquina superior derecha)
3. Ver√°s todos los requests en tiempo real
```

**Colab**:
```
Los logs aparecen directamente en el notebook
```

**Render**:
```
1. Dashboard ‚Üí tu servicio
2. "Logs" tab
3. Ver en tiempo real
```

---

## üêõ Troubleshooting

### Problema: "Modelo no carga"

**Soluci√≥n**:
```python
# En app.py, agrega debug:
def load_model():
    import os
    print("Archivos en directorio:", os.listdir("."))
    
    if not os.path.exists("model.keras"):
        print("‚ùå model.keras no encontrado!")
        return False
    
    print("‚úÖ model.keras encontrado")
    model = tf.keras.models.load_model("model.keras")
    # ...
```

### Problema: "Predicciones incorrectas"

**Causas comunes**:
1. **Preprocesamiento incorrecto**
   ```python
   # Prueba diferentes normalizaciones:
   img_array = img_array / 255.0  # 0-1
   # O
   img_array = img_array  # 0-255
   ```

2. **Orden de clases incorrecto**
   ```python
   # Verifica que coincide con tu modelo
   CLASS_NAMES = {0: "Healthy", 1: "Mosaic", ...}
   ```

3. **Tama√±o de imagen**
   ```python
   IMG_SIZE = 224  # Verifica tu modelo
   ```

### Problema: "Request timeout"

**Soluci√≥n**: Aumenta timeout en app:
```typescript
// En apiService.ts
private TIMEOUT = 60000; // 60 segundos
```

### Problema: "CORS error"

Ya est√° solucionado en app.py, pero si persiste:
```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

### Problema: "Out of memory" en GPU

**Soluci√≥n**:
```python
# Limitar memoria de TensorFlow
import tensorflow as tf

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    tf.config.set_logical_device_configuration(
        gpus[0],
        [tf.config.LogicalDeviceConfiguration(memory_limit=4096)]
    )
```

---

## üìä Monitoreo de Uso

### Hugging Face
```
1. Space ‚Üí Settings ‚Üí Usage
2. Ver requests/d√≠a, uso de CPU/GPU
3. L√≠mite: Ilimitado en plan gratuito
```

### Tips de Optimizaci√≥n
1. **Cache de predicciones**: Guarda resultados recientes
2. **Batch processing**: Agrupa m√∫ltiples im√°genes
3. **Compresi√≥n de im√°genes**: Reduce tama√±o antes de enviar
4. **Lazy loading**: Solo carga modelo cuando se necesita

---

## üéØ Recomendaci√≥n Final

Para producci√≥n ‚Üí **Hugging Face Spaces**:
- Permanente 24/7
- GPU gratis
- URLs estables
- F√°cil actualizaci√≥n

Para testing r√°pido ‚Üí **Google Colab**:
- Setup en 5 minutos
- GPU potente
- Bueno para experimentar

Para backup ‚Üí **Render**:
- Alternativa si HF falla
- Solo CPU pero funcional

---

## üìû Recursos Adicionales

- [Docs Hugging Face Spaces](https://huggingface.co/docs/hub/spaces)
- [FastAPI Tutorial](https://fastapi.tiangolo.com/tutorial/)
- [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)
- [ngrok Docs](https://ngrok.com/docs)
- [Render Docs](https://render.com/docs)

---

¬°√âxito con tu deployment! üöÄüåæ
